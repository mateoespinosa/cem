trials: 5
results_dir: "results/celeba_interventions/"
# DATASET VARIABLES
dataset: "celeba"
image_size: 64
num_classes: 1000
batch_size: 512
root_dir: /home/xty20/data
use_imbalance: True
use_binary_vector_class: True
num_concepts: 6
label_binary_width: 1
label_dataset_subsample: 12
num_hidden_concepts: 2
selected_concepts: False
num_workers: 8
competence_levels: [1, 0]

# Intervention Parameters
intervention_freq: 1
intervention_batch_size: 1024
intervention_policies:
    - "intcem_policy"
    - "behavioural_cloning_no_prior"
    - "optimal_greedy_no_prior"
    - "group_optimal_global_no_prior"

shared_params:
    top_k_accuracy: [3, 5, 10]
    save_model: True
    max_epochs: 200
    patience: 15
    emb_size: 16
    extra_dims: 0
    concept_loss_weight: 1
    learning_rate: 0.005
    weight_decay: 0.000004
    weight_loss: False
    c_extractor_arch: resnet34
    optimizer: sgd
    bool: False
    early_stopping_monitor: val_loss
    early_stopping_mode: min
    early_stopping_delta: 0.0
    momentum: 0.9
    sigmoidal_prob: False
    training_intervention_prob: 0.25


runs:
    - architecture: 'ConceptEmbeddingModel'
      extra_name: ""
      shared_prob_gen: True
      sigmoidal_prob: True
      sigmoidal_embedding: False
      training_intervention_prob: 0.25
      concat_prob: False
      embedding_activation: "leakyrelu"

    - architecture: "IntAwareConceptEmbeddingModel"
      extra_name: "Retry_intervention_weight_{intervention_weight}_horizon_rate_{horizon_rate}_intervention_discount_{intervention_discount}_task_discount_{intervention_task_discount}"
      training_intervention_prob: 0.25
      horizon_binary_representation:  True
      include_task_trajectory_loss: True
      include_only_last_trajectory_loss: True
      task_loss_weight: 0
      intervention_weight: [5,1,0.1,0]
      intervention_task_loss_weight: 1
      initial_horizon: 2
      use_concept_groups: True # DIFF False
      use_full_mask_distr: False
      propagate_target_gradients: False
      int_model_use_bn: True
      int_model_layers: [128,128,64,64]
      intcem_task_loss_weight: 0
      embedding_activation: "leakyrelu"
      tau: 1
      max_horizon: 6
      horizon_uniform_distr: True
      beta_a: 1
      beta_b: 3
      intervention_task_discount: [1.5, 1.1]
      average_trajectory: True
      use_horizon: False # DIFF True
      initialize_discount: False
      model_pretrain_path: null
      horizon_rate: 1.005
      intervention_discount: 1
      legacy_mode: False # Diff True
      gradient_clip_val: 50  # DIFF from last ones too!! Before no gradient clipping was done
      grid_variables:
          - intervention_task_discount
          - intervention_weight
      grid_search_mode: exhaustive

    - architecture: 'ConceptBottleneckModel'
      extra_name: "Sigmoid"
      sigmoidal_embedding: False
      training_intervention_prob: 0.25
      concat_prob: False
      embedding_activation: "leakyrelu"
      bool: False
      extra_dims: 0
      sigmoidal_extra_capacity: False
      sigmoidal_prob: True